{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247199f-2cdd-403d-87df-1b2444f755c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP1 컘으로 video 촬영 후 저장하여 pose video로 변환b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "296514b6-90cc-4635-98bb-9367000ec734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23215"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -q \"openvino-dev>=2024.0.0\"\n",
    "%pip install -q tensorflow\n",
    "%pip install -q opencv-python requests tqdm\n",
    "\n",
    "# Fetch `notebook_utils` module\n",
    "import requests\n",
    "\n",
    "r = requests.get(\n",
    "    url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py\",\n",
    ")\n",
    "\n",
    "open(\"notebook_utils.py\", \"w\").write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0043ce1a-d522-47ad-b265-c56df656d2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23215"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import tarfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import openvino as ov\n",
    "from openvino.tools import mo\n",
    "from openvino.tools.mo.front import tf as ov_tf_front\n",
    "\n",
    "import notebook_utils as utils\n",
    "\n",
    "# Fetch `notebook_utils` module\n",
    "import requests\n",
    "\n",
    "r = requests.get(\n",
    "    url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py\",\n",
    ")\n",
    "\n",
    "open(\"notebook_utils.py\", \"w\").write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e033ac-c5a3-4243-8b53-1f08b764ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A directory where the model will be downloaded.\n",
    "base_model_dir = Path(\"model\")\n",
    "\n",
    "# The name of the model from Open Model Zoo.\n",
    "model_name = \"human-pose-estimation-0001\"\n",
    "# Selected precision (FP32, FP16, FP16-INT8).\n",
    "precision = \"FP16-INT8\"\n",
    "\n",
    "model_path = base_model_dir / \"intel\" / model_name / precision / f\"{model_name}.xml\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    model_url_dir = f\"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/3/{model_name}/{precision}/\"\n",
    "    utils.download_file(model_url_dir + model_name + \".xml\", model_path.name, model_path.parent)\n",
    "    utils.download_file(\n",
    "        model_url_dir + model_name + \".bin\",\n",
    "        model_path.with_suffix(\".bin\").name,\n",
    "        model_path.parent,\n",
    "    )\n",
    "\n",
    "# code from https://github.com/openvinotoolkit/open_model_zoo/blob/9296a3712069e688fe64ea02367466122c8e8a3b/demos/common/python/models/open_pose.py#L135\n",
    "class OpenPoseDecoder:\n",
    "    BODY_PARTS_KPT_IDS = (\n",
    "        (1, 2),\n",
    "        (1, 5),\n",
    "        (2, 3),\n",
    "        (3, 4),\n",
    "        (5, 6),\n",
    "        (6, 7),\n",
    "        (1, 8),\n",
    "        (8, 9),\n",
    "        (9, 10),\n",
    "        (1, 11),\n",
    "        (11, 12),\n",
    "        (12, 13),\n",
    "        (1, 0),\n",
    "        (0, 14),\n",
    "        (14, 16),\n",
    "        (0, 15),\n",
    "        (15, 17),\n",
    "        (2, 16),\n",
    "        (5, 17),\n",
    "    )\n",
    "    BODY_PARTS_PAF_IDS = (\n",
    "        12,\n",
    "        20,\n",
    "        14,\n",
    "        16,\n",
    "        22,\n",
    "        24,\n",
    "        0,\n",
    "        2,\n",
    "        4,\n",
    "        6,\n",
    "        8,\n",
    "        10,\n",
    "        28,\n",
    "        30,\n",
    "        34,\n",
    "        32,\n",
    "        36,\n",
    "        18,\n",
    "        26,\n",
    "    )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_joints=18,\n",
    "        skeleton=BODY_PARTS_KPT_IDS,\n",
    "        paf_indices=BODY_PARTS_PAF_IDS,\n",
    "        max_points=100,\n",
    "        score_threshold=0.1,\n",
    "        min_paf_alignment_score=0.05,\n",
    "        delta=0.5,\n",
    "    ):\n",
    "        self.num_joints = num_joints\n",
    "        self.skeleton = skeleton\n",
    "        self.paf_indices = paf_indices\n",
    "        self.max_points = max_points\n",
    "        self.score_threshold = score_threshold\n",
    "        self.min_paf_alignment_score = min_paf_alignment_score\n",
    "        self.delta = delta\n",
    "\n",
    "        self.points_per_limb = 10\n",
    "        self.grid = np.arange(self.points_per_limb, dtype=np.float32).reshape(1, -1, 1)\n",
    "\n",
    "    def __call__(self, heatmaps, nms_heatmaps, pafs):\n",
    "        batch_size, _, h, w = heatmaps.shape\n",
    "        assert batch_size == 1, \"Batch size of 1 only supported\"\n",
    "\n",
    "        keypoints = self.extract_points(heatmaps, nms_heatmaps)\n",
    "        pafs = np.transpose(pafs, (0, 2, 3, 1))\n",
    "\n",
    "        if self.delta > 0:\n",
    "            for kpts in keypoints:\n",
    "                kpts[:, :2] += self.delta\n",
    "                np.clip(kpts[:, 0], 0, w - 1, out=kpts[:, 0])\n",
    "                np.clip(kpts[:, 1], 0, h - 1, out=kpts[:, 1])\n",
    "\n",
    "        pose_entries, keypoints = self.group_keypoints(keypoints, pafs, pose_entry_size=self.num_joints + 2)\n",
    "        poses, scores = self.convert_to_coco_format(pose_entries, keypoints)\n",
    "        if len(poses) > 0:\n",
    "            poses = np.asarray(poses, dtype=np.float32)\n",
    "            poses = poses.reshape((poses.shape[0], -1, 3))\n",
    "        else:\n",
    "            poses = np.empty((0, 17, 3), dtype=np.float32)\n",
    "            scores = np.empty(0, dtype=np.float32)\n",
    "\n",
    "        return poses, scores\n",
    "\n",
    "    def extract_points(self, heatmaps, nms_heatmaps):\n",
    "        batch_size, channels_num, h, w = heatmaps.shape\n",
    "        assert batch_size == 1, \"Batch size of 1 only supported\"\n",
    "        assert channels_num >= self.num_joints\n",
    "\n",
    "        xs, ys, scores = self.top_k(nms_heatmaps)\n",
    "        masks = scores > self.score_threshold\n",
    "        all_keypoints = []\n",
    "        keypoint_id = 0\n",
    "        for k in range(self.num_joints):\n",
    "            # Filter low-score points.\n",
    "            mask = masks[0, k]\n",
    "            x = xs[0, k][mask].ravel()\n",
    "            y = ys[0, k][mask].ravel()\n",
    "            score = scores[0, k][mask].ravel()\n",
    "            n = len(x)\n",
    "            if n == 0:\n",
    "                all_keypoints.append(np.empty((0, 4), dtype=np.float32))\n",
    "                continue\n",
    "            # Apply quarter offset to improve localization accuracy.\n",
    "            x, y = self.refine(heatmaps[0, k], x, y)\n",
    "            np.clip(x, 0, w - 1, out=x)\n",
    "            np.clip(y, 0, h - 1, out=y)\n",
    "            # Pack resulting points.\n",
    "            keypoints = np.empty((n, 4), dtype=np.float32)\n",
    "            keypoints[:, 0] = x\n",
    "            keypoints[:, 1] = y\n",
    "            keypoints[:, 2] = score\n",
    "            keypoints[:, 3] = np.arange(keypoint_id, keypoint_id + n)\n",
    "            keypoint_id += n\n",
    "            all_keypoints.append(keypoints)\n",
    "        return all_keypoints\n",
    "\n",
    "    def top_k(self, heatmaps):\n",
    "        N, K, _, W = heatmaps.shape\n",
    "        heatmaps = heatmaps.reshape(N, K, -1)\n",
    "        # Get positions with top scores.\n",
    "        ind = heatmaps.argpartition(-self.max_points, axis=2)[:, :, -self.max_points :]\n",
    "        scores = np.take_along_axis(heatmaps, ind, axis=2)\n",
    "        # Keep top scores sorted.\n",
    "        subind = np.argsort(-scores, axis=2)\n",
    "        ind = np.take_along_axis(ind, subind, axis=2)\n",
    "        scores = np.take_along_axis(scores, subind, axis=2)\n",
    "        y, x = np.divmod(ind, W)\n",
    "        return x, y, scores\n",
    "\n",
    "    @staticmethod\n",
    "    def refine(heatmap, x, y):\n",
    "        h, w = heatmap.shape[-2:]\n",
    "        valid = np.logical_and(np.logical_and(x > 0, x < w - 1), np.logical_and(y > 0, y < h - 1))\n",
    "        xx = x[valid]\n",
    "        yy = y[valid]\n",
    "        dx = np.sign(heatmap[yy, xx + 1] - heatmap[yy, xx - 1], dtype=np.float32) * 0.25\n",
    "        dy = np.sign(heatmap[yy + 1, xx] - heatmap[yy - 1, xx], dtype=np.float32) * 0.25\n",
    "        x = x.astype(np.float32)\n",
    "        y = y.astype(np.float32)\n",
    "        x[valid] += dx\n",
    "        y[valid] += dy\n",
    "        return x, y\n",
    "\n",
    "    @staticmethod\n",
    "    def is_disjoint(pose_a, pose_b):\n",
    "        pose_a = pose_a[:-2]\n",
    "        pose_b = pose_b[:-2]\n",
    "        return np.all(np.logical_or.reduce((pose_a == pose_b, pose_a < 0, pose_b < 0)))\n",
    "\n",
    "    def update_poses(\n",
    "        self,\n",
    "        kpt_a_id,\n",
    "        kpt_b_id,\n",
    "        all_keypoints,\n",
    "        connections,\n",
    "        pose_entries,\n",
    "        pose_entry_size,\n",
    "    ):\n",
    "        for connection in connections:\n",
    "            pose_a_idx = -1\n",
    "            pose_b_idx = -1\n",
    "            for j, pose in enumerate(pose_entries):\n",
    "                if pose[kpt_a_id] == connection[0]:\n",
    "                    pose_a_idx = j\n",
    "                if pose[kpt_b_id] == connection[1]:\n",
    "                    pose_b_idx = j\n",
    "            if pose_a_idx < 0 and pose_b_idx < 0:\n",
    "                # Create new pose entry.\n",
    "                pose_entry = np.full(pose_entry_size, -1, dtype=np.float32)\n",
    "                pose_entry[kpt_a_id] = connection[0]\n",
    "                pose_entry[kpt_b_id] = connection[1]\n",
    "                pose_entry[-1] = 2\n",
    "                pose_entry[-2] = np.sum(all_keypoints[connection[0:2], 2]) + connection[2]\n",
    "                pose_entries.append(pose_entry)\n",
    "            elif pose_a_idx >= 0 and pose_b_idx >= 0 and pose_a_idx != pose_b_idx:\n",
    "                # Merge two poses are disjoint merge them, otherwise ignore connection.\n",
    "                pose_a = pose_entries[pose_a_idx]\n",
    "                pose_b = pose_entries[pose_b_idx]\n",
    "                if self.is_disjoint(pose_a, pose_b):\n",
    "                    pose_a += pose_b\n",
    "                    pose_a[:-2] += 1\n",
    "                    pose_a[-2] += connection[2]\n",
    "                    del pose_entries[pose_b_idx]\n",
    "            elif pose_a_idx >= 0 and pose_b_idx >= 0:\n",
    "                # Adjust score of a pose.\n",
    "                pose_entries[pose_a_idx][-2] += connection[2]\n",
    "            elif pose_a_idx >= 0:\n",
    "                # Add a new limb into pose.\n",
    "                pose = pose_entries[pose_a_idx]\n",
    "                if pose[kpt_b_id] < 0:\n",
    "                    pose[-2] += all_keypoints[connection[1], 2]\n",
    "                pose[kpt_b_id] = connection[1]\n",
    "                pose[-2] += connection[2]\n",
    "                pose[-1] += 1\n",
    "            elif pose_b_idx >= 0:\n",
    "                # Add a new limb into pose.\n",
    "                pose = pose_entries[pose_b_idx]\n",
    "                if pose[kpt_a_id] < 0:\n",
    "                    pose[-2] += all_keypoints[connection[0], 2]\n",
    "                pose[kpt_a_id] = connection[0]\n",
    "                pose[-2] += connection[2]\n",
    "                pose[-1] += 1\n",
    "        return pose_entries\n",
    "\n",
    "    @staticmethod\n",
    "    def connections_nms(a_idx, b_idx, affinity_scores):\n",
    "        # From all retrieved connections that share starting/ending keypoints leave only the top-scoring ones.\n",
    "        order = affinity_scores.argsort()[::-1]\n",
    "        affinity_scores = affinity_scores[order]\n",
    "        a_idx = a_idx[order]\n",
    "        b_idx = b_idx[order]\n",
    "        idx = []\n",
    "        has_kpt_a = set()\n",
    "        has_kpt_b = set()\n",
    "        for t, (i, j) in enumerate(zip(a_idx, b_idx)):\n",
    "            if i not in has_kpt_a and j not in has_kpt_b:\n",
    "                idx.append(t)\n",
    "                has_kpt_a.add(i)\n",
    "                has_kpt_b.add(j)\n",
    "        idx = np.asarray(idx, dtype=np.int32)\n",
    "        return a_idx[idx], b_idx[idx], affinity_scores[idx]\n",
    "\n",
    "    def group_keypoints(self, all_keypoints_by_type, pafs, pose_entry_size=20):\n",
    "        all_keypoints = np.concatenate(all_keypoints_by_type, axis=0)\n",
    "        pose_entries = []\n",
    "        # For every limb.\n",
    "        for part_id, paf_channel in enumerate(self.paf_indices):\n",
    "            kpt_a_id, kpt_b_id = self.skeleton[part_id]\n",
    "            kpts_a = all_keypoints_by_type[kpt_a_id]\n",
    "            kpts_b = all_keypoints_by_type[kpt_b_id]\n",
    "            n = len(kpts_a)\n",
    "            m = len(kpts_b)\n",
    "            if n == 0 or m == 0:\n",
    "                continue\n",
    "\n",
    "            # Get vectors between all pairs of keypoints, i.e. candidate limb vectors.\n",
    "            a = kpts_a[:, :2]\n",
    "            a = np.broadcast_to(a[None], (m, n, 2))\n",
    "            b = kpts_b[:, :2]\n",
    "            vec_raw = (b[:, None, :] - a).reshape(-1, 1, 2)\n",
    "\n",
    "            # Sample points along every candidate limb vector.\n",
    "            steps = 1 / (self.points_per_limb - 1) * vec_raw\n",
    "            points = steps * self.grid + a.reshape(-1, 1, 2)\n",
    "            points = points.round().astype(dtype=np.int32)\n",
    "            x = points[..., 0].ravel()\n",
    "            y = points[..., 1].ravel()\n",
    "\n",
    "            # Compute affinity score between candidate limb vectors and part affinity field.\n",
    "            part_pafs = pafs[0, :, :, paf_channel : paf_channel + 2]\n",
    "            field = part_pafs[y, x].reshape(-1, self.points_per_limb, 2)\n",
    "            vec_norm = np.linalg.norm(vec_raw, ord=2, axis=-1, keepdims=True)\n",
    "            vec = vec_raw / (vec_norm + 1e-6)\n",
    "            affinity_scores = (field * vec).sum(-1).reshape(-1, self.points_per_limb)\n",
    "            valid_affinity_scores = affinity_scores > self.min_paf_alignment_score\n",
    "            valid_num = valid_affinity_scores.sum(1)\n",
    "            affinity_scores = (affinity_scores * valid_affinity_scores).sum(1) / (valid_num + 1e-6)\n",
    "            success_ratio = valid_num / self.points_per_limb\n",
    "\n",
    "            # Get a list of limbs according to the obtained affinity score.\n",
    "            valid_limbs = np.where(np.logical_and(affinity_scores > 0, success_ratio > 0.8))[0]\n",
    "            if len(valid_limbs) == 0:\n",
    "                continue\n",
    "            b_idx, a_idx = np.divmod(valid_limbs, n)\n",
    "            affinity_scores = affinity_scores[valid_limbs]\n",
    "\n",
    "            # Suppress incompatible connections.\n",
    "            a_idx, b_idx, affinity_scores = self.connections_nms(a_idx, b_idx, affinity_scores)\n",
    "            connections = list(\n",
    "                zip(\n",
    "                    kpts_a[a_idx, 3].astype(np.int32),\n",
    "                    kpts_b[b_idx, 3].astype(np.int32),\n",
    "                    affinity_scores,\n",
    "                )\n",
    "            )\n",
    "            if len(connections) == 0:\n",
    "                continue\n",
    "\n",
    "            # Update poses with new connections.\n",
    "            pose_entries = self.update_poses(\n",
    "                kpt_a_id,\n",
    "                kpt_b_id,\n",
    "                all_keypoints,\n",
    "                connections,\n",
    "                pose_entries,\n",
    "                pose_entry_size,\n",
    "            )\n",
    "\n",
    "        # Remove poses with not enough points.\n",
    "        pose_entries = np.asarray(pose_entries, dtype=np.float32).reshape(-1, pose_entry_size)\n",
    "        pose_entries = pose_entries[pose_entries[:, -1] >= 3]\n",
    "        return pose_entries, all_keypoints\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_coco_format(pose_entries, all_keypoints):\n",
    "        num_joints = 17\n",
    "        coco_keypoints = []\n",
    "        scores = []\n",
    "        for pose in pose_entries:\n",
    "            if len(pose) == 0:\n",
    "                continue\n",
    "            keypoints = np.zeros(num_joints * 3)\n",
    "            reorder_map = [0, -1, 6, 8, 10, 5, 7, 9, 12, 14, 16, 11, 13, 15, 2, 1, 4, 3]\n",
    "            person_score = pose[-2]\n",
    "            for keypoint_id, target_id in zip(pose[:-2], reorder_map):\n",
    "                if target_id < 0:\n",
    "                    continue\n",
    "                cx, cy, score = 0, 0, 0  # keypoint not found\n",
    "                if keypoint_id != -1:\n",
    "                    cx, cy, score = all_keypoints[int(keypoint_id), 0:3]\n",
    "                keypoints[target_id * 3 + 0] = cx\n",
    "                keypoints[target_id * 3 + 1] = cy\n",
    "                keypoints[target_id * 3 + 2] = score\n",
    "            coco_keypoints.append(keypoints)\n",
    "            scores.append(person_score * max(0, (pose[-1] - 1)))  # -1 for 'neck'\n",
    "        return np.asarray(coco_keypoints), np.asarray(scores)\n",
    "\n",
    "decoder = OpenPoseDecoder()\n",
    "\n",
    "# 2D pooling in numpy (from: https://stackoverflow.com/a/54966908/1624463)\n",
    "def pool2d(A, kernel_size, stride, padding, pool_mode=\"max\"):\n",
    "    \"\"\"\n",
    "    2D Pooling\n",
    "\n",
    "    Parameters:\n",
    "        A: input 2D array\n",
    "        kernel_size: int, the size of the window\n",
    "        stride: int, the stride of the window\n",
    "        padding: int, implicit zero paddings on both sides of the input\n",
    "        pool_mode: string, 'max' or 'avg'\n",
    "    \"\"\"\n",
    "    # Padding\n",
    "    A = np.pad(A, padding, mode=\"constant\")\n",
    "\n",
    "    # Window view of A\n",
    "    output_shape = (\n",
    "        (A.shape[0] - kernel_size) // stride + 1,\n",
    "        (A.shape[1] - kernel_size) // stride + 1,\n",
    "    )\n",
    "    kernel_size = (kernel_size, kernel_size)\n",
    "    A_w = as_strided(\n",
    "        A,\n",
    "        shape=output_shape + kernel_size,\n",
    "        strides=(stride * A.strides[0], stride * A.strides[1]) + A.strides,\n",
    "    )\n",
    "    A_w = A_w.reshape(-1, *kernel_size)\n",
    "\n",
    "    # Return the result of pooling.\n",
    "    if pool_mode == \"max\":\n",
    "        return A_w.max(axis=(1, 2)).reshape(output_shape)\n",
    "    elif pool_mode == \"avg\":\n",
    "        return A_w.mean(axis=(1, 2)).reshape(output_shape)\n",
    "\n",
    "\n",
    "# non maximum suppression\n",
    "def heatmap_nms(heatmaps, pooled_heatmaps):\n",
    "    return heatmaps * (heatmaps == pooled_heatmaps)\n",
    "\n",
    "\n",
    "# Get poses from results.\n",
    "def process_results(img, pafs, heatmaps):\n",
    "    # This processing comes from\n",
    "    # https://github.com/openvinotoolkit/open_model_zoo/blob/master/demos/common/python/models/open_pose.py\n",
    "    pooled_heatmaps = np.array([[pool2d(h, kernel_size=3, stride=1, padding=1, pool_mode=\"max\") for h in heatmaps[0]]])\n",
    "    nms_heatmaps = heatmap_nms(heatmaps, pooled_heatmaps)\n",
    "\n",
    "    # Decode poses.\n",
    "    poses, scores = decoder(heatmaps, nms_heatmaps, pafs)\n",
    "    output_shape = list(compiled_model.output(index=0).partial_shape)\n",
    "    output_scale = (\n",
    "        img.shape[1] / output_shape[3].get_length(),\n",
    "        img.shape[0] / output_shape[2].get_length(),\n",
    "    )\n",
    "    # Multiply coordinates by a scaling factor.\n",
    "    poses[:, :, :2] *= output_scale\n",
    "    return poses, scores\n",
    "\n",
    "colors = (\n",
    "    (255, 0, 0),\n",
    "    (255, 0, 255),\n",
    "    (170, 0, 255),\n",
    "    (255, 0, 85),\n",
    "    (255, 0, 170),\n",
    "    (85, 255, 0),\n",
    "    (255, 170, 0),\n",
    "    (0, 255, 0),\n",
    "    (255, 255, 0),\n",
    "    (0, 255, 85),\n",
    "    (170, 255, 0),\n",
    "    (0, 85, 255),\n",
    "    (0, 255, 170),\n",
    "    (0, 0, 255),\n",
    "    (0, 255, 255),\n",
    "    (85, 0, 255),\n",
    "    (0, 170, 255),\n",
    ")\n",
    "\n",
    "default_skeleton = (\n",
    "    (15, 13),\n",
    "    (13, 11),\n",
    "    (16, 14),\n",
    "    (14, 12),\n",
    "    (11, 12),\n",
    "    (5, 11),\n",
    "    (6, 12),\n",
    "    (5, 6),\n",
    "    (5, 7),\n",
    "    (6, 8),\n",
    "    (7, 9),\n",
    "    (8, 10),\n",
    "    (1, 2),\n",
    "    (0, 1),\n",
    "    (0, 2),\n",
    "    (1, 3),\n",
    "    (2, 4),\n",
    "    (3, 5),\n",
    "    (4, 6),\n",
    ")\n",
    "\n",
    "\n",
    "def draw_poses(img, poses, point_score_threshold, skeleton=default_skeleton):\n",
    "    if poses.size == 0:\n",
    "        return img\n",
    "\n",
    "    img_limbs = np.copy(img)\n",
    "    for pose in poses:\n",
    "        points = pose[:, :2].astype(np.int32)\n",
    "        points_scores = pose[:, 2]\n",
    "        # Draw joints.\n",
    "        for i, (p, v) in enumerate(zip(points, points_scores)):\n",
    "            if v > point_score_threshold:\n",
    "                cv2.circle(img, tuple(p), 1, colors[i], 2)\n",
    "        # Draw limbs.\n",
    "        for i, j in skeleton:\n",
    "            if points_scores[i] > point_score_threshold and points_scores[j] > point_score_threshold:\n",
    "                cv2.line(\n",
    "                    img_limbs,\n",
    "                    tuple(points[i]),\n",
    "                    tuple(points[j]),\n",
    "                    color=colors[j],\n",
    "                    thickness=4,\n",
    "                )\n",
    "    cv2.addWeighted(img, 0.4, img_limbs, 0.6, 0, dst=img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55c9176-c61e-4357-8320-c9139adcc95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data', ['Mconv7_stage2_L1', 'Mconv7_stage2_L2'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### pose estimation set up\n",
    "import ipywidgets as widgets\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value=\"AUTO\",\n",
    "    description=\"Device:\",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "device\n",
    "\n",
    "# Initialize OpenVINO Runtime\n",
    "core = ov.Core()\n",
    "# Read the network from a file.\n",
    "model = core.read_model(model_path)\n",
    "# Let the AUTO device decide where to load the model (you can use CPU, GPU as well).\n",
    "compiled_model = core.compile_model(model=model, device_name=device.value, config={\"PERFORMANCE_HINT\": \"LATENCY\"})\n",
    "\n",
    "# Get the input and output names of nodes.\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layers = compiled_model.outputs\n",
    "\n",
    "# Get the input size.\n",
    "height, width = list(input_layer.shape)[2:]\n",
    "\n",
    "input_layer.any_name, [o.any_name for o in output_layers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bedf0a-a905-4fbb-b3de-d814d16e6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 촬영 한 video를 pose video 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1325dc-6a54-4067-956e-6ed70739674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "pafs_output_key = compiled_model.output(\"Mconv7_stage2_L1\")\n",
    "heatmaps_output_key = compiled_model.output(\"Mconv7_stage2_L2\")\n",
    "# 저장한 동영상 파일 열기\n",
    "cap = cv2.VideoCapture('./resource/video/2_cropped.mp4')\n",
    "\n",
    "# 동영상 파일 열기 확인\n",
    "if not cap.isOpened():\n",
    "    print(\"동영상 파일을 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 동영상 파일의 프레임 너비와 높이 가져오기\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# VideoWriter 객체 생성 - 동영상 재생을 위한 창\n",
    "cv2.namedWindow('Saved Video', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Saved Video', frame_width, frame_height)\n",
    "out = cv2.VideoWriter('./resource/video/2_cropped_pose.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 25, (frame_width, frame_height))\n",
    "\n",
    "# 동영상 재생\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame2 = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
    "\n",
    "    input_img = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    input_img = input_img.transpose((2, 0, 1))[np.newaxis, ...]\n",
    "    results = compiled_model([input_img])\n",
    "    pafs = results[pafs_output_key]\n",
    "    heatmaps = results[heatmaps_output_key]\n",
    "    poses, scores = process_results(frame2, pafs, heatmaps)\n",
    "    frame2 = draw_poses(frame2, poses, 0.1)\n",
    "    \n",
    "    out.write(frame2)  # 프레임을 동영상 파일에 쓰기\n",
    "    cv2.imshow('Saved Video', frame2)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc6619-f5fb-4f45-9614-dff359f933e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### pose video 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c01212e-a886-48dd-8174-0741678bcbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동영상 파일을 열 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 저장한 동영상 파일 열기\n",
    "cap = cv2.VideoCapture('../resource/video/2_cropped_pose.mp4')\n",
    "\n",
    "# 동영상 파일 열기 확인\n",
    "if not cap.isOpened():\n",
    "    print(\"동영상 파일을 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 동영상 파일의 프레임 너비와 높이 가져오기\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# VideoWriter 객체 생성 - 동영상 재생을 위한 창\n",
    "cv2.namedWindow('Saved Video', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Saved Video', frame_width, frame_height)\n",
    "\n",
    "# 동영상 재생\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    " \n",
    "    cv2.imshow('Saved Video', frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c927b1d-2c6d-4728-b93f-fd80cc6a9dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
